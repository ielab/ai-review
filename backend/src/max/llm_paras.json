{
  "model_name": "gpt-4o",
  "temperature": 0,
  "max_tokens": 2048,
  "response_format": "text",
  "streaming": true
}